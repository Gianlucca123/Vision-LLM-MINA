# Installation et Lancement de VILA

Ce guide explique comment installer et lancer **VILA** sur la carte **Jetson Orin Nano**.

Nous avons suivi le tutoriel du laboratoire NVIDIA pour r√©aliser cette installation : [https://www.jetson-ai-lab.com/tutorial_nano-vlm.html](#)

## 1. Installation de NanoLLM et VILA

Ex√©cutez la commande suivante pour installer et ex√©cuter **NanoLLM** et **VILA** :

```bash
jetson-containers run $(autotag nano_llm) \
  python3 -m nano_llm.chat --api=mlc \
    --model Efficient-Large-Model/VILA1.5-3b \
    --max-context-len 64 \
    --max-new-tokens 32
```
Apr√®s installation, le mod√®le VILA sera automatiquement lanc√© et vous pourrez le questionner.

## 2. Questionner VILA sur une image

**Remarque :** Les images doivent √™tre plac√©es dans le r√©pertoire `jetson-containers/data/images/`.

Pour lui poser des questions, √©crire dans l'interface ouverte apr√®s lancement :
```bash
>> PROMPT: /data/images/mon_image.png

>> PROMPT: Je pose ma question ici.
```

N'h√©sitez pas √† r√©initialiser le questionnement pour fournir une autre image ou √©viter que le mod√®le ne se base sur ses r√©ponses pr√©c√©dentes √† l'aide de **reset** :
```bash
>> PROMPT: reset
```

### Pr√©parer des prompts en avance

Vous pouvez structurer vos questions en amont comme suit :

```bash
jetson-containers run $(autotag nano_llm) \
  python3 -m nano_llm.chat --api=mlc \
    --model Efficient-Large-Model/VILA1.5-3b \
    --max-context-len 256 \
    --max-new-tokens 32 \
    --prompt '/data/images/hoover.jpg' \
    --prompt 'what does the road sign say?' \
    --prompt 'what kind of environment is it?' \
    --prompt 'reset' \
    --prompt '/data/images/lake.jpg' \
    --prompt 'please describe the scene.' \
    --prompt 'are there any hazards to be aware of?'
```

üìå **Note :**
- Le premier prompt doit contenir le chemin de l'image √† analyser.
- Le mot-cl√© `reset` permet de r√©initialiser l'historique de discussion et de soumettre une nouvelle image.

## 3. Questionner VILA en mode direct

```bash
jetson-containers run $(autotag nano_llm) \
  python3 -m nano_llm.agents.video_query --api=mlc \
    --model Efficient-Large-Model/VILA1.5-3b \
    --max-context-len 256 \
    --max-new-tokens 32 \
    --video-input /dev/video0 \
    --video-output webrtc://@:8554/output
```

---

Ce guide fournit une proc√©dure claire pour utiliser **VILA** sur la **Jetson Orin Nano**. Pour plus de d√©tails, reportez-vous √† la documentation officielle de NVIDIA.
